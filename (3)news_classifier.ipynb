{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(3)news_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM24TYQVbWuDatYKqWKdYXY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/misogynyX/Data_reclassification/blob/master/(3)news_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvCR5orG_fHJ",
        "colab_type": "code",
        "outputId": "9d37f96e-58d4-4a47-c2da-a0c3a35d72b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "# 4/0AGWRjPNN6oSJJpYQR_5Jj7ssUkHKpuB7cuCFRjapsXRFU5gcIvS_AI\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtlEoV0__oqC",
        "colab_type": "code",
        "outputId": "ac4d500d-d766-4a01-b436-dc6aa2a2d49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yahU8IpGAGfy",
        "colab_type": "code",
        "outputId": "0d075a56-59cd-47d2-f619-a186c465d65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/60)\u001b[K\rremote: Counting objects:   3% (2/60)\u001b[K\rremote: Counting objects:   5% (3/60)\u001b[K\rremote: Counting objects:   6% (4/60)\u001b[K\rremote: Counting objects:   8% (5/60)\u001b[K\rremote: Counting objects:  10% (6/60)\u001b[K\rremote: Counting objects:  11% (7/60)\u001b[K\rremote: Counting objects:  13% (8/60)\u001b[K\rremote: Counting objects:  15% (9/60)\u001b[K\rremote: Counting objects:  16% (10/60)\u001b[K\rremote: Counting objects:  18% (11/60)\u001b[K\rremote: Counting objects:  20% (12/60)\u001b[K\rremote: Counting objects:  21% (13/60)\u001b[K\rremote: Counting objects:  23% (14/60)\u001b[K\rremote: Counting objects:  25% (15/60)\u001b[K\rremote: Counting objects:  26% (16/60)\u001b[K\rremote: Counting objects:  28% (17/60)\u001b[K\rremote: Counting objects:  30% (18/60)\u001b[K\rremote: Counting objects:  31% (19/60)\u001b[K\rremote: Counting objects:  33% (20/60)\u001b[K\rremote: Counting objects:  35% (21/60)\u001b[K\rremote: Counting objects:  36% (22/60)\u001b[K\rremote: Counting objects:  38% (23/60)\u001b[K\rremote: Counting objects:  40% (24/60)\u001b[K\rremote: Counting objects:  41% (25/60)\u001b[K\rremote: Counting objects:  43% (26/60)\u001b[K\rremote: Counting objects:  45% (27/60)\u001b[K\rremote: Counting objects:  46% (28/60)\u001b[K\rremote: Counting objects:  48% (29/60)\u001b[K\rremote: Counting objects:  50% (30/60)\u001b[K\rremote: Counting objects:  51% (31/60)\u001b[K\rremote: Counting objects:  53% (32/60)\u001b[K\rremote: Counting objects:  55% (33/60)\u001b[K\rremote: Counting objects:  56% (34/60)\u001b[K\rremote: Counting objects:  58% (35/60)\u001b[K\rremote: Counting objects:  60% (36/60)\u001b[K\rremote: Counting objects:  61% (37/60)\u001b[K\rremote: Counting objects:  63% (38/60)\u001b[K\rremote: Counting objects:  65% (39/60)\u001b[K\rremote: Counting objects:  66% (40/60)\u001b[K\rremote: Counting objects:  68% (41/60)\u001b[K\rremote: Counting objects:  70% (42/60)\u001b[K\rremote: Counting objects:  71% (43/60)\u001b[K\rremote: Counting objects:  73% (44/60)\u001b[K\rremote: Counting objects:  75% (45/60)\u001b[K\rremote: Counting objects:  76% (46/60)\u001b[K\rremote: Counting objects:  78% (47/60)\u001b[K\rremote: Counting objects:  80% (48/60)\u001b[K\rremote: Counting objects:  81% (49/60)\u001b[K\rremote: Counting objects:  83% (50/60)\u001b[K\rremote: Counting objects:  85% (51/60)\u001b[K\rremote: Counting objects:  86% (52/60)\u001b[K\rremote: Counting objects:  88% (53/60)\u001b[K\rremote: Counting objects:  90% (54/60)\u001b[K\rremote: Counting objects:  91% (55/60)\u001b[K\rremote: Counting objects:  93% (56/60)\u001b[K\rremote: Counting objects:  95% (57/60)\u001b[K\rremote: Counting objects:  96% (58/60)\u001b[K\rremote: Counting objects:  98% (59/60)\u001b[K\rremote: Counting objects: 100% (60/60)\u001b[K\rremote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/55)\u001b[K\rremote: Compressing objects:   3% (2/55)\u001b[K\rremote: Compressing objects:   5% (3/55)\u001b[K\rremote: Compressing objects:   7% (4/55)\u001b[K\rremote: Compressing objects:   9% (5/55)\u001b[K\rremote: Compressing objects:  10% (6/55)\u001b[K\rremote: Compressing objects:  12% (7/55)\u001b[K\rremote: Compressing objects:  14% (8/55)\u001b[K\rremote: Compressing objects:  16% (9/55)\u001b[K\rremote: Compressing objects:  18% (10/55)\u001b[K\rremote: Compressing objects:  20% (11/55)\u001b[K\rremote: Compressing objects:  21% (12/55)\u001b[K\rremote: Compressing objects:  23% (13/55)\u001b[K\rremote: Compressing objects:  25% (14/55)\u001b[K\rremote: Compressing objects:  27% (15/55)\u001b[K\rremote: Compressing objects:  29% (16/55)\u001b[K\rremote: Compressing objects:  30% (17/55)\u001b[K\rremote: Compressing objects:  32% (18/55)\u001b[K\rremote: Compressing objects:  34% (19/55)\u001b[K\rremote: Compressing objects:  36% (20/55)\u001b[K\rremote: Compressing objects:  38% (21/55)\u001b[K\rremote: Compressing objects:  40% (22/55)\u001b[K\rremote: Compressing objects:  41% (23/55)\u001b[K\rremote: Compressing objects:  43% (24/55)\u001b[K\rremote: Compressing objects:  45% (25/55)\u001b[K\rremote: Compressing objects:  47% (26/55)\u001b[K\rremote: Compressing objects:  49% (27/55)\u001b[K\rremote: Compressing objects:  50% (28/55)\u001b[K\rremote: Compressing objects:  52% (29/55)\u001b[K\rremote: Compressing objects:  54% (30/55)\u001b[K\rremote: Compressing objects:  56% (31/55)\u001b[K\rremote: Compressing objects:  58% (32/55)\u001b[K\rremote: Compressing objects:  60% (33/55)\u001b[K\rremote: Compressing objects:  61% (34/55)\u001b[K\rremote: Compressing objects:  63% (35/55)\u001b[K\rremote: Compressing objects:  65% (36/55)\u001b[K\rremote: Compressing objects:  67% (37/55)\u001b[K\rremote: Compressing objects:  69% (38/55)\u001b[K\rremote: Compressing objects:  70% (39/55)\u001b[K\rremote: Compressing objects:  72% (40/55)\u001b[K\rremote: Compressing objects:  74% (41/55)\u001b[K\rremote: Compressing objects:  76% (42/55)\u001b[K\rremote: Compressing objects:  78% (43/55)\u001b[K\rremote: Compressing objects:  80% (44/55)\u001b[K\rremote: Compressing objects:  81% (45/55)\u001b[K\rremote: Compressing objects:  83% (46/55)\u001b[K\rremote: Compressing objects:  85% (47/55)\u001b[K\rremote: Compressing objects:  87% (48/55)\u001b[K\rremote: Compressing objects:  89% (49/55)\u001b[K\rremote: Compressing objects:  90% (50/55)\u001b[K\rremote: Compressing objects:  92% (51/55)\u001b[K\rremote: Compressing objects:  94% (52/55)\u001b[K\rremote: Compressing objects:  96% (53/55)\u001b[K\rremote: Compressing objects:  98% (54/55)\u001b[K\rremote: Compressing objects: 100% (55/55)\u001b[K\rremote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "Unpacking objects:   1% (1/60)   \rUnpacking objects:   3% (2/60)   \rUnpacking objects:   5% (3/60)   \rUnpacking objects:   6% (4/60)   \rUnpacking objects:   8% (5/60)   \rUnpacking objects:  10% (6/60)   \rUnpacking objects:  11% (7/60)   \rUnpacking objects:  13% (8/60)   \rUnpacking objects:  15% (9/60)   \rUnpacking objects:  16% (10/60)   \rUnpacking objects:  18% (11/60)   \rUnpacking objects:  20% (12/60)   \rUnpacking objects:  21% (13/60)   \rUnpacking objects:  23% (14/60)   \rUnpacking objects:  25% (15/60)   \rUnpacking objects:  26% (16/60)   \rUnpacking objects:  28% (17/60)   \rUnpacking objects:  30% (18/60)   \rUnpacking objects:  31% (19/60)   \rUnpacking objects:  33% (20/60)   \rUnpacking objects:  35% (21/60)   \rUnpacking objects:  36% (22/60)   \rUnpacking objects:  38% (23/60)   \rUnpacking objects:  40% (24/60)   \rUnpacking objects:  41% (25/60)   \rUnpacking objects:  43% (26/60)   \rUnpacking objects:  45% (27/60)   \rUnpacking objects:  46% (28/60)   \rUnpacking objects:  48% (29/60)   \rUnpacking objects:  50% (30/60)   \rUnpacking objects:  51% (31/60)   \rremote: Total 60 (delta 23), reused 20 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects:  53% (32/60)   \rUnpacking objects:  55% (33/60)   \rUnpacking objects:  56% (34/60)   \rUnpacking objects:  58% (35/60)   \rUnpacking objects:  60% (36/60)   \rUnpacking objects:  61% (37/60)   \rUnpacking objects:  63% (38/60)   \rUnpacking objects:  65% (39/60)   \rUnpacking objects:  66% (40/60)   \rUnpacking objects:  68% (41/60)   \rUnpacking objects:  70% (42/60)   \rUnpacking objects:  71% (43/60)   \rUnpacking objects:  73% (44/60)   \rUnpacking objects:  75% (45/60)   \rUnpacking objects:  76% (46/60)   \rUnpacking objects:  78% (47/60)   \rUnpacking objects:  80% (48/60)   \rUnpacking objects:  81% (49/60)   \rUnpacking objects:  83% (50/60)   \rUnpacking objects:  85% (51/60)   \rUnpacking objects:  86% (52/60)   \rUnpacking objects:  88% (53/60)   \rUnpacking objects:  90% (54/60)   \rUnpacking objects:  91% (55/60)   \rUnpacking objects:  93% (56/60)   \rUnpacking objects:  95% (57/60)   \rUnpacking objects:  96% (58/60)   \rUnpacking objects:  98% (59/60)   \rUnpacking objects: 100% (60/60)   \rUnpacking objects: 100% (60/60), done.\n",
            "/content/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.5)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.4)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2020-06-09 09:58:51--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.1, 18.205.93.0, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Sdb6Y44NjhU48RaNOnuncdMll34%3D&Expires=1591698532&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n",
            "--2020-06-09 09:58:52--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Sdb6Y44NjhU48RaNOnuncdMll34%3D&Expires=1591698532&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.136.164\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.136.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.54MB/s    in 0.2s    \n",
            "\n",
            "2020-06-09 09:58:52 (7.54 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2020-06-09 09:59:11--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.0, 18.205.93.1, 18.205.93.2, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2FCGFUk%2BYPvuLN3CSbKbIjxDG08Y%3D&Expires=1591697491&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n",
            "--2020-06-09 09:59:11--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=%2FCGFUk%2BYPvuLN3CSbKbIjxDG08Y%3D&Expires=1591697491&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.95.27\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.95.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  71.0MB/s    in 0.7s    \n",
            "\n",
            "2020-06-09 09:59:12 (71.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hIp1nwY_osP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfWQdLrcATal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "from konlpy.tag import Mecab\n",
        "from nltk import FreqDist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZF__tOEMCX8",
        "colab_type": "code",
        "outputId": "ed68d806-b6e8-46c4-a05e-207097b8245b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT8FXTnjMC-O",
        "colab_type": "code",
        "outputId": "f702ee1e-0c0f-4319-b1ad-f4ee5e355239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLyKgEfF_owC",
        "colab_type": "code",
        "outputId": "b5ba3806-e196-439a-9df2-0daa8301c29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP_again_project/train_data.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP_again_project/test_data.csv\")\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2972, 2)\n",
            "(1275, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut_poGZkdX1S",
        "colab_type": "code",
        "outputId": "8595b7e1-f9a0-4752-f2eb-afd4c5a752ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train[train['label'] == 1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blMPZVyx_o2Q",
        "colab_type": "code",
        "outputId": "e1b8c126-789e-4f20-dbc8-eccec3cd2137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = train['text']\n",
        "# sentences_M = train['text']\n",
        "sentences[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    삶과 추억 추억의 마구왕 독고탁 아빠하늘로 은퇴독고탁 캐릭터로 유명한 만화가 이상무...\n",
              "1    새해 소망 빌어요 울산 간절곶 해맞이 인파 인산인해앵커 시청자 여러분 안녕하십니까 ...\n",
              "2    품성은 금메달 아냐사재혁 후배 전치 6주 폭행 앵커멘트 2008년 베이징올림픽 남자...\n",
              "3    독사에 물리고도 공연 이어가 인니 profession여가수profession 끝내 ...\n",
              "4    직업계 고교생 30로 늘려 대학진학률 낮춘다2022년까지 특성화고교마이스터고교 등 ...\n",
              "5    대통령 4년차새해 국정운영 방향은경제 활성화일자리 창출뉴시스정일환 기자  박근혜 대...\n",
              "6    스마트폰이 되고 싶은 아이스마트폰을 놓지 못하는 부모서울신문 나우뉴스 엄마 아빠가 ...\n",
              "7    모바일 신인류 k세대 백마디 말보다 이모티콘 하나상형문자 세대 1 남자  집에 잘 ...\n",
              "8    인도서 흑인 gender여대생gender 몰매봉변 당해외교문제 비화뉴델리연합뉴스 나...\n",
              "9    뉴스 따라잡기 골프채가 부러질 때까지 이번엔 demonize악마demonize 선배...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fVbA8rb_o6v",
        "colab_type": "code",
        "outputId": "93eafd74-c877-4dba-89e6-87043226ae7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 삶과 추억 추억의 마구왕 독고탁 아빠하늘로 은퇴독고탁 캐릭터로 유명한 만화가 이상무본명 박노철씨가 3일 오전 심장마비로 별세했다 71세 고인은 최근 매일 새벽 서울 공덕동 작업실로 출근하며 가수 전인권씨와의 협력작업과 만화 단행본 발간을 준비 중이었다고 한다 평소 술담배를 하지 않고 건강을 챙겼으나 이날 갑자기 세상을 떠 주변을 안타깝게 했다 경북 김천에서 태어나 김천농고를 졸업한 고 [SEP]',\n",
              " '[CLS] 새해 소망 빌어요 울산 간절곶 해맞이 인파 인산인해앵커 시청자 여러분 안녕하십니까 1월 1일 금요일 jtbc 뉴스 아침앤입니다 희망찬 2016년 첫날 아침 어떤 모습으로 맞고 계신지 궁금합니다 새해에도 복 많이 받으시고요 가정에 늘 건강과 행복이 깃들길 기원하겠습니다 저희 아침앤은 올해도 생생한 뉴스 진실된 뉴스로 시청자 여러분을 매일 아침 맞이하겠습니다 올 한해 계속해서 많은 사랑과 [SEP]',\n",
              " '[CLS] 품성은 금메달 아냐사재혁 후배 전치 6주 폭행 앵커멘트 2008년 베이징올림픽 남자 역도 금메달리스트였던 사재혁 선수가 후배를 폭행해 물의를 빚고 있습니다품성은 금메달이 아니었나 봅니다김순철 기자가 보도합니다  기자 한국 남자 역도 최중량급 기대주인 20살 황우만 씨입니다 얼굴 곳곳에 피멍 자국이 선명하고 왼쪽 눈가의 뼈가 부서져 내려 앉았습니다 올림픽 금메달리스트이자 학교 선배 [SEP]',\n",
              " '[CLS] 독사에 물리고도 공연 이어가 인니 profession여가수profession 끝내 사망 앵커  인도네시아 유명 profession여가수profession가 공연 중에 코브라에 물렸습니다 45분 뒤에 무대에서 숨졌는데요 물린 뒤에도 의연한 모습 잃지 않고 해독제 미룬 채 계속 노래했던 게 문제였습니다 서민수 특파원입니다  리포트  인도네시아의 대중가요인 당둣을 부르며 킹코브라와 춤을 추는 29살의 유명 여가수 이르마 불레 인도네시아 서자바섬의 한 마 [SEP]',\n",
              " '[CLS] 직업계 고교생 30로 늘려 대학진학률 낮춘다2022년까지 특성화고교마이스터고교 등 직업계 고교의 학생 수는 현행 수준인 33만 명 수준으로 유지된다 대신 일반계 고교의 정원은 bearing저출산bearing 여파에 따른 학생 수 감소에 맞춰 대폭 줄어든다 교육부는 올해부터 직업교육 학교의 학생 수를 유지하는 방안을 20일 박근혜 대통령에게 보고했다 현재 특성화고마이스터고 등 직업교육 고교 학생 수인 33만 명은 [SEP]',\n",
              " '[CLS] 대통령 4년차새해 국정운영 방향은경제 활성화일자리 창출뉴시스정일환 기자  박근혜 대통령의 병신년 새해 최대 현안은 지난해와 마찬가지로 경제 활성화와 일자리 창출이 될 것으로 예상된다 성장률 하락세가 지속되면서 경제환경이 위기국면으로 접어들어 세대간 계층간 갈등이 심화되고 사회불안도 증폭되고 있기 때문이다 박 대통령은 이를 감안 신년사를 통 [SEP]',\n",
              " '[CLS] 스마트폰이 되고 싶은 아이스마트폰을 놓지 못하는 부모서울신문 나우뉴스 엄마 아빠가 날 더 사랑하도록 스마트폰이 되고 싶어요 인터넷상에 공개된 한 어린 학생의 소원이 많은 이들의 가슴을 먹먹하게 만들고 있다 싱가포르 뉴스 사이트 올 싱가포르 스터프는 최근 싱가포르 한 초등학교 profession여교사profession의 체험담을 소개했다 이 교사는 어느 날 저녁을 먹은 뒤 반 아이들이 제출한 숙제를 확인했을 때 있었던 일을 밝혔다 [SEP]',\n",
              " '[CLS] 모바일 신인류 k세대 백마디 말보다 이모티콘 하나상형문자 세대 1 남자  집에 잘 왔어 여자  응 잘 들어왔어 남자  자기 화났어 ㅠㅠㅠㅠ 이 대화에서 남자친구는 왜 뜬금없이 여자친구가 화났을 것이라고 추측했을까 평소와 달리 아무런 이모티콘이 없었기 때문이다 잘 들어왔다는 말에 여자친구의 이모티콘이 붙은 대화와 비교해보자 감정 없는 말은 싫다 모바일 [SEP]',\n",
              " '[CLS] 인도서 흑인 gender여대생gender 몰매봉변 당해외교문제 비화뉴델리연합뉴스 나확진 특파원  인도 남부에서 아프리카 탄자니아 출신 흑인 gender여대생gender 3명이 현지 주민들에 의해 집단 구타당하고 옷이 찢기는 등 봉변을 당한 것으로 알려져 외교문제로 비화됐다 4일 일간 타임스오브인디아 등에 따르면 지난달 31일 오후 7시30분현지시간 인도 남부 카르나타카 주 벵갈루루에서 탄자니아 여대생과 친구 3명이 차를 타고 가다 [SEP]',\n",
              " '[CLS] 뉴스 따라잡기 골프채가 부러질 때까지 이번엔 demonize악마demonize 선배앵커 멘트 제자를 때리고 강제로 인분까지 먹인 교수 동기생에게 집 청소를 시키고  성적 학대까지 한 동기생 기억하십니까 demonize악마demonize 교수 악마 동기생이란 이름으로 불리며 사회에 충격을 주었는데요 이런 엽기적인 사건이 이번엔 서울의 한  명문 사립대 대학원에서 일어났습니다 선배가 후배를 골프채로 때리고 변기에 든 물을 마시게 하는 등 가혹행위를 해왔다 [SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHlV1Ay9_o46",
        "colab_type": "code",
        "outputId": "43351845-9ece-4374-d2c3-ecab7655f6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 라벨 추출\n",
        "labels = train['label'].values\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRM2rKX8AY34",
        "colab_type": "text"
      },
      "source": [
        "### 토크나이징\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcSS48FcQ_K6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Mecab_tok(sentence):\n",
        "  # 불용어 정의\n",
        "  stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','속보','특보','기자','trivialize','demonize','molka','porn','abuse','metoo','bearing','gender','profession']\n",
        "  # 사용 언어 정의 \n",
        "  userWords = ['일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드']\n",
        "  \n",
        "  # Mecab으로 문장을 토큰으로 분리\n",
        "  tokenizer = Mecab()\n",
        "\n",
        "  ### train 사용 코드\n",
        "  tokenized_texts=['[CLS]']\n",
        "  temp = []\n",
        "  temp = tokenizer.morphs(sentence)\n",
        "  temp = [word for word in temp if not word in stopwords]\n",
        "  tokenized_texts.extend(temp)\n",
        "  tokenized_texts.append('[SEP]')\n",
        "\n",
        "  return tokenized_texts\n",
        "\n",
        "# tokenized_texts = Mecab_tok(sentences_M)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xkH6Dol_ouh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 불용어 정의\n",
        "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','속보','특보','기자','trivialize','demonize','molka','porn','abuse','metoo','bearing','gender','profession']\n",
        "# 사용 언어 정의 \n",
        "userWords = ['일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGRi0S4LI2Nh",
        "colab_type": "code",
        "outputId": "1768a514-b842-4163-9059-3908419ebe31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#Bert Tocknizer 로 문장을 토큰화하기\n",
        "def BertTok(sentences):\n",
        "  # 불용어 정의\n",
        "  stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','속보','특보','기자','trivialize','demonize','molka','porn','abuse','metoo','bearing','gender','profession']\n",
        "  # 사용 언어 정의 \n",
        "  userWords = ['일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드']\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  tokenized_texts= [word for word in tokenized_texts if not word in stopwords]\n",
        "  return tokenized_texts\n",
        "\n",
        "tokenized_texts = BertTok(sentences)\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 삶과 추억 추억의 마구왕 독고탁 아빠하늘로 은퇴독고탁 캐릭터로 유명한 만화가 이상무본명 박노철씨가 3일 오전 심장마비로 별세했다 71세 고인은 최근 매일 새벽 서울 공덕동 작업실로 출근하며 가수 전인권씨와의 협력작업과 만화 단행본 발간을 준비 중이었다고 한다 평소 술담배를 하지 않고 건강을 챙겼으나 이날 갑자기 세상을 떠 주변을 안타깝게 했다 경북 김천에서 태어나 김천농고를 졸업한 고 [SEP]\n",
            "['[CLS]', '삶', '##과', '추', '##억', '추', '##억', '##의', '마', '##구', '##왕', '독', '##고', '##탁', '아', '##빠', '##하', '##늘', '##로', '은', '##퇴', '##독', '##고', '##탁', '캐', '##릭', '##터', '##로', '유', '##명한', '만', '##화가', '이상', '##무', '##본', '##명', '박', '##노', '##철', '##씨', '##가', '3일', '오', '##전', '심', '##장', '##마', '##비', '##로', '별', '##세', '##했다', '71', '##세', '고', '##인은', '최', '##근', '매', '##일', '새', '##벽', '서울', '공', '##덕', '##동', '작', '##업', '##실', '##로', '출', '##근', '##하며', '가수', '전', '##인', '##권', '##씨', '##와의', '협', '##력', '##작', '##업', '##과', '만', '##화', '단', '##행', '##본', '발', '##간을', '준', '##비', '중', '##이었다', '##고', '한다', '평', '##소', '술', '##담', '##배', '##를', '하지', '않고', '건', '##강', '##을', '챙', '##겼', '##으나', '이', '##날', '갑', '##자', '##기', '세', '##상을', '떠', '주', '##변', '##을', '안', '##타', '##깝', '##게', '했다', '경', '##북', '김', '##천', '##에서', '태', '##어', '##나', '김', '##천', '##농', '##고', '##를', '졸업', '##한', '고', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlZFmNGYKEN3",
        "colab_type": "code",
        "outputId": "599db2de-86a3-42dc-f588-f5ec45139fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9409,  11882,   9765,  91837,   9765,  91837,  10459,\n",
              "         9246,  17196,  40991,   9088,  11664, 119335,   9519, 119008,\n",
              "        35506, 118762,  11261,   9632, 119362,  80331,  11664, 119335,\n",
              "         9792,  73352,  21876,  11261,   9625,  68414,   9248, 110817,\n",
              "        66982,  32537,  40419,  16758,   9319,  28981,  47465,  49212,\n",
              "        11287,  45367,   9580,  16617,   9491,  13890,  23811,  29455,\n",
              "        11261,   9353,  24982,  12490,  12513,  24982,   8888,  88236,\n",
              "         9764,  50248,   9258,  18392,   9415, 118984,  48253,   8896,\n",
              "       118782,  18778,   9652,  26784,  31503,  11261,   9768,  50248,\n",
              "        22766, 108399,   9665,  12030,  25347,  49212,  92019,   9981,\n",
              "        28143,  38709,  26784,  11882,   9248,  18227,   9059,  25549,\n",
              "        40419,   9323,  90295,   9691,  29455,   9694,  58926,  11664,\n",
              "        16139,   9926,  22333,   9463, 105462,  76036,  11513,  89093,\n",
              "        45593,   8865,  47181,  10622,   9743, 118637,  35466,   9638,\n",
              "        41919,   8849,  13764,  12310,   9435,  33654,   9138,   9689,\n",
              "       118985,  10622,   9521,  22695, 118676,  14153,  23622,   8885])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPU-1a6QAvYi",
        "colab_type": "code",
        "outputId": "acdfbf59-4b08-4fd1-d54d-31d6c624dda1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duwQZIxbAvVy",
        "colab_type": "code",
        "outputId": "f8d024ea-beae-44a6-ed00-c4d966b5309d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   9485,  18623, 119418, 119405,  90833,   9415,  14523,   9766,\n",
            "         16617,   8907,  51745, 119153,  14523,  12092,   9450, 119199,  11664,\n",
            "           100,   9313, 119248,  61320,  30842,  34951,   8896,  20626,  25549,\n",
            "         30005,   9462,  50632,   9576,  11664,   9344,  10739, 119233,  25486,\n",
            "         33188,  90947,   9638,  54867, 119027,   9891,  46150,  14279,   9485,\n",
            "         18623, 119418,  45397,  93222,  16323,  40958,  11882,   9378,  17342,\n",
            "         48446,  22458,  31401,   9935,  90833,  62834,  70672,  10739,   9415,\n",
            "         14523,   9640,  32159,   9689,  11664, 118965,  24098,   9694,  30873,\n",
            "          8845,   9487, 118958,  38851,  10739,   9583,   9954,  14523,  35979,\n",
            "         77039,  64749,  48599,   8870,  96972,   9576,  11664,  12490,  18329,\n",
            "         45397,  28000,  21386,  21928,   8932,  20595,  12508,   9640,  36553,\n",
            "         54903,  12638,   9487,  18227,  43022,  25387,  10530,  59355,   9485,\n",
            "          9689,  40958,  10892,   9665,  41919,   9935,  90833,  70672,  26212,\n",
            "          9323, 119057,  11102,   9487,  10954,   9640,  32159,   9879,    102,\n",
            "             0,      0])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        0., 0.])\n",
            "tensor([   101,   9069,  27506,  18227,  36210, 119270,  12310, 119351,  30873,\n",
            "          9415,  14523,   9351, 118802,  17655,   9706,  17196, 119268,   9546,\n",
            "         15891,  18471,   9537, 106826,   9415,  14523,   9351, 118802,  17655,\n",
            "          9706,  17196, 119268,  10739,   9546,  15891,  18471, 119424, 119081,\n",
            "         48345,   9949,  12692, 119415,  23635,   9381,  36553,  11287,  11489,\n",
            "          9835, 118992,  10739,   8982,   9711,    122,  38631,  29935,   9738,\n",
            "         11287,   9368,  22695,  30936,   9640,  16758,  97146,  14523,  11287,\n",
            "          9646, 118825, 118854,  11664,   9638,  12605,  17342,  96720,  11882,\n",
            "          9519,  28396,  11287,  25503,  12605,  66554,  23635,   9866,  30873,\n",
            "         11287,   9323,  24017, 119424, 119081,  48345,   9657,  22458,  18392,\n",
            "         60886,  58303,  48345,   9238,  55530,  15184,   9949,  12692, 119415,\n",
            "         69283,   9246, 118768, 101743,   9381,  36553, 119268,  10739,    100,\n",
            "          9993, 119144,  10530,  10012, 119089, 119147, 119081,  48345,   9711,\n",
            "           122,  38631,  29935,   9738,  11287,   9368,  10530,   9845,  30936,\n",
            "          9689,  36553])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khiTOdKwA3Qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ3E1QGULLJR",
        "colab_type": "code",
        "outputId": "e87ff35e-55c9-4710-fed7-2fc664fdb7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  9 09:59:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    62W / 149W |   6638MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv2-PtFNA3Pf",
        "colab_type": "code",
        "outputId": "63044e29-2d32-4104-d06c-f0c1357646af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GU11W7X6fut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.load_state_dict(torch.load(f'/content/drive/My Drive/Colab Notebooks/NLP_again_project/best_accuracy.pth'))\n",
        "# model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWyV8t60A3M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 20\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5JTs3pUA3KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8heToD0wBGC0",
        "colab_type": "text"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTPXJywA3Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtECT4zDBIf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AygcRw1EBId2",
        "colab_type": "code",
        "outputId": "d0a1b880-db60-4a4a-fd85-758d4964f743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:01:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:01:46\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hKu-fa_4piJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.save(model.state_dict(), f'/content/drive/My Drive/Colab Notebooks/NLP_again_project/best_accuracy.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF4iaZkZwad0",
        "colab_type": "text"
      },
      "source": [
        "# test 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E01E9VgswayN",
        "colab_type": "code",
        "outputId": "977aef2d-b4f8-4505-829a-67d3098f1d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = test['text']\n",
        "sentences[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    실험실의 신화 이진아 이은경 소극장 산울림 30년사 한국 연극계의 거목 임영웅80 ...\n",
              "1    간추린 단신  3대 경제성장 회복법안 처리 뒷받침돼야 외안종범 청와대 경제수석은 올...\n",
              "2    먼저 옷 벗고 강간당했다 무고50대 여성 집유전주뉴스1 박효익 기자  전주지법 형사...\n",
              "3    북 새해 방송도 체제선전김정은 특집부터 노래 경연까지 앵커멘트 연말연시 북한 방송은...\n",
              "4    푸틴의 정적 제거법성관계 molka몰카molka 공개kgb 출신인 푸틴 러시아 대통...\n",
              "5    서울시민 경제분야 최대 관심사는 체감물가 상승연령대별로 전월세값 상승노후대비 미비로...\n",
              "6    치솟는 월세에 초선의원 보트 숙박동아일보 영국 런던의 집세를 감당하지 못해 보트에서...\n",
              "7    이스라엘 총기난사아프간 폭탄테러곳곳 테러 몸살 많은 사람들이 희망과 기대 속에 새해...\n",
              "8    테러단체 조직원 모집 영상에 도널드 트럼프 등장알샤바브 미국 내 인종차별 증거로 트...\n",
              "9    포전차공격헬기도발 원점 초토화 앵커멘트 시청자 여러분께서는 어떤 목표를 세우며 새해...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWyfQIJwwarF",
        "colab_type": "code",
        "outputId": "c70d3ec9-f246-465b-e64f-a5dc86b38965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# 라벨 추출\n",
        "labels = test['label'].values\n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjEf1P0tw6IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mecab_tok(sentence):\n",
        "  # 불용어 정의\n",
        "  stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','속보','특보','기자','trivialize','demonize','molka','porn','abuse','metoo','bearing','gender','profession']\n",
        "  # 사용 언어 정의 \n",
        "  userWords = ['일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드','일베','메갈리아','워마드']\n",
        "  \n",
        "  # Mecab으로 문장을 토큰으로 분리\n",
        "  tokenizer = Mecab()\n",
        "\n",
        "  ### train 사용 코드\n",
        "  tokenized_texts=['[CLS]']\n",
        "  temp = []\n",
        "  temp = tokenizer.morphs(sentence)\n",
        "  temp = [word for word in temp if not word in stopwords]\n",
        "  tokenized_texts.extend(temp)\n",
        "  tokenized_texts.append('[SEP]')\n",
        "\n",
        "  return tokenized_texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_c5Y07uwm12",
        "colab_type": "code",
        "outputId": "dfd3f797-b836-4204-9b12-70ca3e3e3af2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "# tokenized_texts = [tokenizer(sent) for sent in sentences]\n",
        "tokenized_texts = BertTok(sentences)\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "실험실의 신화 이진아 이은경 소극장 산울림 30년사 한국 연극계의 거목 임영웅80 극단 산울림 대표와 불문학자 겸 번역가인 부인 오증자77서울여대 명예교수가 10년만 버텨보자며 홍대 근처에 마련한 소극장 산울림이 올해 31주년을 맞았다 누나 임수진53이 극장장 동생 수현51이 예술감독을 맡아 역사를 잇고 있다 연극평론가인 이진아 숙명여자대학교 교수와\n",
            "['실', '##험', '##실', '##의', '신', '##화', '이', '##진', '##아', '이', '##은', '##경', '소', '##극', '##장', '산', '##울', '##림', '30', '##년', '##사', '한국', '연', '##극', '##계', '##의', '거', '##목', '임', '##영', '##웅', '##80', '극', '##단', '산', '##울', '##림', '대', '##표', '##와', '불', '##문', '##학자', '겸', '번', '##역', '##가', '##인', '부', '##인', '오', '##증', '##자', '##7', '##7', '##서', '##울', '##여', '##대', '명', '##예', '##교', '##수가', '10', '##년', '##만', '[UNK]', '홍', '##대', '근', '##처', '##에', '마', '##련', '##한', '소', '##극', '##장', '산', '##울', '##림', '##이', '올', '##해', '31', '##주', '##년', '##을', '맞', '##았다', '누', '##나', '임', '##수', '##진', '##53', '##이', '극', '##장', '##장', '동', '##생', '수', '##현', '##51', '##이', '예', '##술', '##감', '##독', '##을', '맡', '##아', '역', '##사를', '잇', '##고', '있다', '연', '##극', '##평', '##론', '##가', '##인', '이', '##진', '##아', '숙', '##명', '##여', '##자', '##대학교', '교', '##수', '##와']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQ5AybeOwm0I",
        "colab_type": "code",
        "outputId": "ca55dd99-5d75-4ea4-a012-016b87c520c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  9489,  86834,  31503,  10459,   9487,  18227,   9638,  18623,\n",
              "        16985,   9638,  10892,  31720,   9448,  63243,  13890,   9407,\n",
              "        78123,  67527,  10244,  10954,  12945,  48556,   9568,  63243,\n",
              "        21611,  10459,   8863,  68055,   9644,  30858, 119171,  44026,\n",
              "         8925,  24989,   9407,  78123,  67527,   9069,  37824,  12638,\n",
              "         9368,  25934, 109522,   8882,   9338,  23160,  11287,  12030,\n",
              "         9365,  12030,   9580, 119230,  13764,  11305,  11305,  12424,\n",
              "        78123,  29935,  14423,   9281,  96279,  25242,  73894,  10150,\n",
              "        10954,  19105,    100,   9992,  14423,   8926,  60469,  10530,\n",
              "         9246, 101440,  11102,   9448,  63243,  13890,   9407,  78123,\n",
              "        67527,  10739,   9583,  14523,  10413,  16323,  10954,  10622,\n",
              "         9256,  27303,   9032,  16439,   9644,  15891,  18623,  67574,\n",
              "        10739,   8925,  13890,  13890,   9095,  24017,   9460,  30842,\n",
              "        77581,  10739,   9576,  51945, 105197,  80331,  10622,   9257,\n",
              "        16985,   9566,  32159,   9646,  11664,  11506,   9568,  63243,\n",
              "       119398,  42769,  11287,  12030,   9638,  18623,  16985,   9461])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ipLn4_ywmyz",
        "colab_type": "code",
        "outputId": "2d5e9580-12a3-4e74-b254-034f90bed46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgKYYzmJwmxY",
        "colab_type": "code",
        "outputId": "9644971d-5c35-4816-989f-6eb655270189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  9489,  86834,  31503,  10459,   9487,  18227,   9638,  18623,  16985,\n",
            "          9638,  10892,  31720,   9448,  63243,  13890,   9407,  78123,  67527,\n",
            "         10244,  10954,  12945,  48556,   9568,  63243,  21611,  10459,   8863,\n",
            "         68055,   9644,  30858, 119171,  44026,   8925,  24989,   9407,  78123,\n",
            "         67527,   9069,  37824,  12638,   9368,  25934, 109522,   8882,   9338,\n",
            "         23160,  11287,  12030,   9365,  12030,   9580, 119230,  13764,  11305,\n",
            "         11305,  12424,  78123,  29935,  14423,   9281,  96279,  25242,  73894,\n",
            "         10150,  10954,  19105,    100,   9992,  14423,   8926,  60469,  10530,\n",
            "          9246, 101440,  11102,   9448,  63243,  13890,   9407,  78123,  67527,\n",
            "         10739,   9583,  14523,  10413,  16323,  10954,  10622,   9256,  27303,\n",
            "          9032,  16439,   9644,  15891,  18623,  67574,  10739,   8925,  13890,\n",
            "         13890,   9095,  24017,   9460,  30842,  77581,  10739,   9576,  51945,\n",
            "        105197,  80331,  10622,   9257,  16985,   9566,  32159,   9646,  11664,\n",
            "         11506,   9568,  63243, 119398,  42769,  11287,  12030,   9638,  18623,\n",
            "         16985,   9461])\n",
            "tensor(0)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE7xw744wmwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWPyIfZA4ChV",
        "colab_type": "text"
      },
      "source": [
        "## 테스트셋 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i0-c59XwmsQ",
        "colab_type": "code",
        "outputId": "43791743-8e7f-4b03-c134-14dc41fa80e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.88\n",
            "Test took: 0:00:17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SWQUDA6wmqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwabTMuIBSzu",
        "colab_type": "text"
      },
      "source": [
        "# 새로운 텍스트 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUuP4IzmBIbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    # tokenized_texts = [mecab_tok(sent) for sent in sentences]\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYk-5yjZBIZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2aV7BSrBIXf",
        "colab_type": "code",
        "outputId": "8b799d18-0c69-491c-916c-a4441c9606d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "logits = test_sentences(['몰래 카메라에 주변인물 깜짝! 지나가던 사람에게 다친 손을 보여주는 한 남자. 몰카였다는 걸 알고 다함께 웃었습니다'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.7421889   0.00711382]]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv4gjXFFBIVU",
        "colab_type": "code",
        "outputId": "0d20a84a-267a-4483-f5be-a3df2db3d2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "logits = test_sentences(['주연배우가 아깝다. 총체적 난국...'])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.25396544 -0.6868521 ]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMk5aKrm7DSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtrwkKTEBITJ",
        "colab_type": "code",
        "outputId": "2b349d3f-65ec-48fb-f7ef-56b4c254243a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "txt_num = 23\n",
        "test_txt = test['text'][txt_num]\n",
        "print(test_txt)\n",
        "print(test['label'][txt_num])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "새해 첫 출근길 스모그 주의마스크 준비하세요 날씨는 포근한데 연일 미세먼지가 말썽입니다 특히 건강에 더 해로운 초미세먼지까지 기승인데요 새해 첫 출근길인 내일도 전국 대부분 지역에서는 미세먼지 농도가 높게 나타나겠습니다 김재훈 기자입니다 기자 희뿌연 먼지에 가려진 하늘이 온통 잿빛으로 변했습니다 먼지는 안개에도 엉겨붙어 가시거리는 평소의 절반 수준까지 떨어졌습니다 국내\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0_kKQsBIRB",
        "colab_type": "code",
        "outputId": "86cc52b4-0517-46e8-9b3d-8530911af68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "logits = test_sentences([test_txt])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.916645  -3.9645553]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5uDbmTzBIPJ",
        "colab_type": "code",
        "outputId": "4a229019-de82-4f9f-bf24-7273c3496ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        }
      },
      "source": [
        "import random\n",
        "a = [random.randint(0,190) for _ in range(10)]\n",
        "for num in a:\n",
        "  test_txt = test['text'][num]\n",
        "  logits = test_sentences([test_txt])\n",
        "  print(test_txt)\n",
        "  print(logits)\n",
        "  aa = test['label'][num] ; bb = np.argmax(logits) \n",
        "\n",
        "  if (aa == bb): cc = '네'\n",
        "  else: cc = \"아니오\"\n",
        "\n",
        "  print( 'true label:{}, predicted label:{} 맞췄는가? :::{}'.format(aa,bb,cc) )\n",
        "\n",
        "  print('-'*40)\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "시선 2035 일베가 되어가는 메갈리아소라넷 젊은 남자라면 한 번쯤 들어봤을 국내 최대 성인 사이트다 최근 회원수 100만이라는 소라넷이 남녀 모두의 주목을 받았다 지난 주말 한 방송이 여성의 신상이 노출된 molka몰카molka 동영상 등의 불법성을 집중 추적하면서다 경찰도 전담 수사팀을 꾸렸다 그런데 불똥은 정반대로 튀었다 소라넷 운영진이 방송에서 메갈리아라는 사이트가 주축이 된 소라넷\n",
            "[[-3.741699   3.7440004]]\n",
            "true label:1, predicted label:1 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "새 희망을 품고하늘에서 본 2016년 첫 날앵커 멘트 어제 하루 많은 분들이 새 희망과 기대를 품고 2016년 새해를 맞이하셨을텐데요 새해 첫 날의 모습을 박민철 기자가 헬기를 타고 둘러봤습니다 리포트 눈 덮인 정상을 향해 힘찬 발걸음을 내딛으며 2016년 첫 하루를 엽니다 정상에 선 시민들은 새해의 정기를 듬뿍 받으며 한해의 각오를 다집니다 물류가 모이는 화물기지에는 휴일이\n",
            "[[ 3.4486861 -3.3527668]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "치솟는 월세에 초선의원 보트 숙박동아일보 영국 런던의 집세를 감당하지 못해 보트에서 자취 생활을 시작한 존 머서 영국 보수당 하원의원왼쪽과 기차에서 생활하는 독일 gender여대생gender 레오니 뮐러 씨 사진 출처 텔레그래프 하늘을 뚫을 듯 치솟는 월세에 일개미 같은 삶에 지쳐 나만의 집을 찾는 세계인들의 사연이 화제다 영국 일간 텔레그래프는 2일 보트에서 먹고 자는 초선 의원의 사연을 소개\n",
            "[[ 3.9141264 -4.0456266]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "권순홍의 음식기행  홍콩 첨자기 tsim chai kee noodle한국인에게 칼국수라는 친숙한 면요리가 있듯이 홍콩을 대표하는 면 요리로는 완탕면이 있다 완탕면은 따뜻한 국물 속에 꼬들꼬들한 식감의 면과 새우만두가 들어간 광둥식 국수인데 간편하게 먹을 수 있고 가격도 저렴해 대중적인 인기가 높아 길거리의 작고 허름한 식당부터 호텔급의 고급 중식당까지 대부분 식당에서 내놓는 홍콩의 국민 메뉴 중 하나이다\n",
            "[[ 3.85931   -3.9755454]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "금주의 공연 이유있는 선택 클래식금호아트홀 신년음악회 외클래식금호아트홀 신년음악회 2016 금호아트홀 상주음악가로 뽑힌 선우예권26피아노이 올해 첫 포문을 연다 그륀펠트 빈의 저녁 모차르트 피아노 소나타 10번 스트라빈스키 페트루슈카 라벨 라 발스 연주 7일 오후 8시 금호아트홀 0263031977 why 해 지는 저녁 빈을 산책하는 듯한 낭만을 선사한다 기대치 \n",
            "[[ 3.8953042 -3.9820104]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "땅 땅 오늘의 판결 워터파크 molka몰카molka범들  징역 3년6개월4년6개월수원지법 형사9단독 김춘화 판사는 수도권 일대 워터파크수영장의 여자 탈의실과 샤워실에서 molka몰래카메라molka를 찍은 혐의로 기소된 gender최모여27gender씨에게 징역 3년6개월을 선고했다 또 최씨에게 동영상 촬영을 지시하고 넘겨받은 영상을 인터넷을 통해 유포한 강모35씨에게는 징역 4년6개월을 선고했다 두 사람에게는 성폭력 치료 프로그램 80시간 이수도 부과됐다\n",
            "[[-3.7340753  3.671037 ]]\n",
            "true label:1, predicted label:1 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "홍기용의 내 인생의 책 5 회색 쇼크  테드 c 피시먼 인구 절벽에서 살아남으려면 인구구조의 급변이 다가오고 있다 고령화와 bearing저출산bearing은 피할 수 없게 되었다 곧 회색 노인이 큰 비중을 차지하는 나라가 될 것이다 25년 후에는 3명 중 1명이 65세 이상의 노인이 된다 고령화는 낮아진 출산율과 높아진 의료수준에 기인하기 때문에 어쩔 수 없는 상황이다 그때는 어떤 세상이 될지 걱정이다\n",
            "[[-3.206056   3.2492504]]\n",
            "true label:0, predicted label:1 맞췄는가? :::아니오\n",
            "----------------------------------------\n",
            "\n",
            "스마트폰으로 자원봉사 참가 신청하세요 스마트폰으로도 자원봉사활동 참가 신청을 할 수 있게 된다 행정자치부는 1365자원봉사포털www1365gokr 내 액티브엑스activex를 제거하는 방식으로 4일부터 모바일 서비스를 제공한다고 3일 밝혔다 1365포털은 자원봉사 정보를 한 곳에 모아놓은 사이트다 자원봉사활동 참여 신청에서부터 실적 관리\n",
            "[[ 2.8558145 -3.3510904]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "판결 인사이드 대법원 여성 상반신 몰래 찍어도 가슴 강조 안 되면 무죄20대 회사원 a씨에게는 은밀한 취미가 있습니다 공공장소에서 여성의 신체 부위를 남몰래 스마트폰으로 찍어두는 겁니다 지하철 1호선5호선 안이나 길거리에서 다리를 꼰채 앉아 있는 앞자리 여성의 하반신허리 부위 등 2013년 11월부터 이듬해 5월까지 49차례 molka몰카molka를 찍었습니다 촬영 당시 여성들은 모두 스타킹이나 레깅스 스키니진 등을 입고 있\n",
            "[[-3.7121649  3.7140977]]\n",
            "true label:1, predicted label:1 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n",
            "못 믿겠다 뿌리깊은 사법 불신국민 71 재판 불공정 법률 컨설팅 경험자일수록 전관예우 판결에 영향 클 것 일반 국민들에게 법원은 별로 신뢰할 수 없는 곳이라는 조사 결과가 나왔다 나이가 어릴수록 법률적 경험과 지식이 있다고 생각할수록 법원과 재판 결과에 대한 불신이 깊었다 머니투데이가 1일 여론조사 전문기관 리얼미터에 의뢰해  조사한 2015 법원 신뢰도 대국\n",
            "[[ 3.9025984 -4.0378475]]\n",
            "true label:0, predicted label:0 맞췄는가? :::네\n",
            "----------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0YxRh4N7RaG",
        "colab_type": "text"
      },
      "source": [
        "# article 을 이용하여 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsVIM1rEFcrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import copy\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLPlI0e57Wgs",
        "colab_type": "code",
        "outputId": "2fedf4bb-19c3-4a18-b205-4378871ccd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# csv 파일 불러오기\n",
        "\n",
        "articles = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP_again_project/articles.csv\")\n",
        "articles.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>cp_name</th>\n",
              "      <th>text</th>\n",
              "      <th>authors</th>\n",
              "      <th>keywords</th>\n",
              "      <th>date</th>\n",
              "      <th>url</th>\n",
              "      <th>tags</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20160101000010878</td>\n",
              "      <td>아시아경제</td>\n",
              "      <td>한민구 국방장관 신년사.. \"군의 존재가치는 싸워 이기는 것\"|사랑하는 국군장병과 ...</td>\n",
              "      <td>양낙규</td>\n",
              "      <td>동북아;한미동맹;통일시대;교육훈련;성과</td>\n",
              "      <td>20160101</td>\n",
              "      <td>https://news.v.daum.net/v/20160101000010878</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20160101000015884</td>\n",
              "      <td>아시아경제</td>\n",
              "      <td>[선거구대란]선거구 실종사태..예비후보자 어떻게 되나| '선거구 실종사태'가 현실화...</td>\n",
              "      <td>유제훈</td>\n",
              "      <td>선거운동;선거구;선거관리위원회;선거구획정;예비후보자</td>\n",
              "      <td>20160101</td>\n",
              "      <td>https://news.v.daum.net/v/20160101000015884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20160101000019894</td>\n",
              "      <td>뉴스1</td>\n",
              "      <td>정의화 \"선거구 비상사태..5일까지 획정안 마련\"..직권상정 돌입|(서울=뉴스1) ...</td>\n",
              "      <td>서미선</td>\n",
              "      <td>선거구;직권상정;정의화;선거구획정;20대총선</td>\n",
              "      <td>20160101</td>\n",
              "      <td>https://news.v.daum.net/v/20160101000019894</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20160101000019895</td>\n",
              "      <td>뉴스1</td>\n",
              "      <td>[총선 D-100]결국 선거구 공백 사태..장기화 가능성도 배제못해| 여야가 20대...</td>\n",
              "      <td>김현</td>\n",
              "      <td>선거구;선거운동;예비후보자;선거관리위원회;총선</td>\n",
              "      <td>20160101</td>\n",
              "      <td>https://news.v.daum.net/v/20160101000019895</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20160101000021904</td>\n",
              "      <td>경향신문</td>\n",
              "      <td>전국 246개 선거구, 결국 사라졌다|전국 246개 국회의원 총선 선거구가 사라지는...</td>\n",
              "      <td>김진우;조미덥</td>\n",
              "      <td>선거구;쟁점법안;성폭력범죄;직권상정;여야</td>\n",
              "      <td>20160101</td>\n",
              "      <td>https://news.v.daum.net/v/20160101000021904</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          article_id cp_name  ... tags label\n",
              "0  20160101000010878   아시아경제  ...  NaN     0\n",
              "1  20160101000015884   아시아경제  ...  NaN     0\n",
              "2  20160101000019894     뉴스1  ...  NaN     0\n",
              "3  20160101000019895     뉴스1  ...  NaN     0\n",
              "4  20160101000021904    경향신문  ...  NaN     0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyhRcGlL7XMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def txt_preprocessing(sample):\n",
        "    sample.drop(['article_id','cp_name','authors','keywords','date','url','tags'],axis = 1, inplace = True)\n",
        "    sample['text'] = sample['text'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]\",\"\")\n",
        "    sample['text'] = sample['text'].str.lower()\n",
        "    \n",
        "    return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BpcZBwf7cVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = copy(articles)\n",
        "sample = txt_preprocessing(sample)\n",
        "sample1 = sample[sample['label']==1]\n",
        "sample1 = sample1.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIvBQ16s7cvZ",
        "colab_type": "code",
        "outputId": "1e61a71d-91b4-4eb8-a250-d25450f7db7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "txt_num = 2362\n",
        "test_txt = sample1['text'][txt_num]\n",
        "logits = test_sentences([test_txt])\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))\n",
        "print(test_txt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.22120564 -0.7779729 ]]\n",
            "0\n",
            "섬마을 학부모들 잇따라 학교 관사 찾아 짐승으로 백기종 전 수서경찰서 강력팀장  김동석 한국교원단체총연합회 대변인 앵커차마 입에 담기도 힘든 끔찍한 일이 작은 섬마을에서 벌어졌죠 전남 신안 섬마을 profession여교사profession 집단 성폭행 사건의 여파가 걷잡을 수 없이 확산되고 있는데요 낙도나 오지로 profession여교사profession 신규발령 내는 걸 가급적 자제하겠다는 대책도 나오는 모양인데 얼마나 효과가 있을지는 물음표입니다 백기\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSx1YGqcxu8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}